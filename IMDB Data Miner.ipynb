{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b96f828",
   "metadata": {},
   "source": [
    "## Getting top bollywood movies form IMDB using webscraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d5a5226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use beautifulSoup to get the latest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efcdf41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87b570df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF to generate urls\n",
    "\n",
    "def url_gen(a):\n",
    "#     a simple miner assist tool to generate URLs \n",
    "#     iterater from range(1, n) where n == R\n",
    "    return 'https://www.imdb.com/search/title/?countries=in&locations=India&count=250&start=' \\\n",
    "                + str( (251) + (a * 250) ) \\\n",
    "                + '&ref_=adv_nxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68e968e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define empty lists to fetch scraped data from the miner\n",
    "bollywood_title_all = []\n",
    "bollywood_year_all = []\n",
    "bollywood_title_links_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03dfddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def miner(url = 'https://www.imdb.com/search/title/?countries=in&locations=India&count=250'\n",
    "          , bollywood_title_all = bollywood_title_all\n",
    "          , bollywood_year_all = bollywood_year_all\n",
    "          , bollywood_title_links_all = bollywood_title_links_all):\n",
    "\n",
    "    # The miner takes in a default URL which is the 1st page to be mined.\n",
    "    # for subsequent mines, we will use the url_gen function to pass in new urls.\n",
    "    # the miner takes in the empty lists by default and updates them through each iteration.\n",
    "    \n",
    "    # Downloading imdb top 250 movie's data\n",
    "    url = url\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "    # use select method and enter the selector path of the element\n",
    "    bollywood_title = (soup.select('div.lister-item-content > h3 > a'))\n",
    "    bollywood_year = (soup.select('div.lister-item-content > h3 > span.lister-item-year.text-muted.unbold'))\n",
    "    bollywood_title_links = [a.attrs.get('href') for a in soup.select('div.lister-item-content > h3 > a')]\n",
    "\n",
    "    # convert bs4.element into string\n",
    "    for i in range(0, len(bollywood_title)):\n",
    "        bollywood_title[i] = bollywood_title[i].text\n",
    "\n",
    "    for i in range(0, len(bollywood_year)):\n",
    "        bollywood_year[i] = bollywood_year[i].text\n",
    "\n",
    "    # Update the empty lists with new mined data in this iteration\n",
    "    bollywood_title_all += bollywood_title\n",
    "    bollywood_year_all += bollywood_year\n",
    "    bollywood_title_links_all += bollywood_title_links "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d88c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mined no. 1 page\n",
      "mined no. 2 page\n",
      "mined no. 3 page\n",
      "mined no. 4 page\n",
      "mined no. 5 page\n",
      "mined no. 6 page\n",
      "mined no. 7 page\n",
      "mined no. 8 page\n",
      "mined no. 9 page\n",
      "mined no. 10 page\n",
      "mined no. 11 page\n",
      "mined no. 12 page\n",
      "mined no. 13 page\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # call the miner with default page\n",
    "    miner()\n",
    "    print('mined no.', 1, 'page' )\n",
    "\n",
    "    # iterate over the next i pages pages:\n",
    "    for i in range(1, 50):\n",
    "        miner(url = url_gen(i))\n",
    "        print('mined no.', i + 1, 'page' )\n",
    "\n",
    "except: \n",
    "    print(\"MINING ERROR !! DATA NOT MINED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4346782",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_for_df = {\"title\":bollywood_title_all, \"release_year\":bollywood_year_all, \"titleId\":bollywood_title_links_all}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9724c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_bollywood = pd.DataFrame(dict_for_df)\n",
    "scraped_bollywood.release_year = scraped_bollywood.release_year.str.extract('(\\d+)')\n",
    "scraped_bollywood.titleId = scraped_bollywood.titleId.str.extract('(\\d+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f5f1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_bollywood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78ee78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_bollywood.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b4d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_basics_raw = pd.read_csv(\"compressed_tsv/title.basics.tsv.gz\" , sep='\\t', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8545f4d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "title_basics_raw.tconst = title_basics_raw.tconst.str.extract('(\\d+)')\n",
    "title_basics_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc23598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if title_basics_raw[title_basics_raw.tconst == '9614490'].shape >(1,1):\n",
    "    print(\"Successfully mined and reconciled\")\n",
    "else:\n",
    "    print(\"FAILED to reconcile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f912d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb79b791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the df as a csv on local machine\n",
    "scraped_bollywood.to_csv('mined_csv/scraped_bollywood.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8293ce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"saved csv to local drive\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
